{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4201001f",
      "metadata": {
        "id": "4201001f"
      },
      "source": [
        "# Getting Wikipedia Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "l2Y8plhhfMk1"
      },
      "id": "l2Y8plhhfMk1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bfc2561",
      "metadata": {
        "id": "2bfc2561"
      },
      "outputs": [],
      "source": [
        "import wikipedia as wiki"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0da0c197",
      "metadata": {
        "id": "0da0c197"
      },
      "outputs": [],
      "source": [
        "search_string = 'Social Network Analysis'\n",
        "\n",
        "page = wiki.page(search_string)\n",
        "\n",
        "content = page.content\n",
        "\n",
        "content[0:680]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a4e5e18",
      "metadata": {
        "id": "6a4e5e18"
      },
      "outputs": [],
      "source": [
        "links = page.links\n",
        "\n",
        "links[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbd2b755",
      "metadata": {
        "id": "cbd2b755"
      },
      "outputs": [],
      "source": [
        "# use this if get error on next cell\n",
        "\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "549748a8",
      "metadata": {
        "id": "549748a8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://en.wikipedia.org/wiki/Social_network_analysis'\n",
        "\n",
        "data = pd.read_html(url)\n",
        "\n",
        "type(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "jnLoRMszftUC"
      },
      "id": "jnLoRMszftUC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1e6dced",
      "metadata": {
        "id": "d1e6dced"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a96fa86",
      "metadata": {
        "id": "9a96fa86"
      },
      "outputs": [],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad31e36a",
      "metadata": {
        "id": "ad31e36a"
      },
      "outputs": [],
      "source": [
        "data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a82ef486",
      "metadata": {
        "id": "a82ef486"
      },
      "outputs": [],
      "source": [
        "url = 'https://en.wikipedia.org/wiki/Crime_in_Oregon'\n",
        "\n",
        "data = pd.read_html(url)\n",
        "\n",
        "df = data[1]\n",
        "\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]"
      ],
      "metadata": {
        "id": "Uyk9zoSrg0jE"
      },
      "id": "Uyk9zoSrg0jE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "id": "2HPpqiUfgnbP"
      },
      "id": "2HPpqiUfgnbP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "id": "x9d9trPxgsAN"
      },
      "id": "x9d9trPxgsAN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "66e99868",
      "metadata": {
        "id": "66e99868"
      },
      "source": [
        "# Project Gutenberg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "id": "6XdER1nShLDM"
      },
      "id": "6XdER1nShLDM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.__version__"
      ],
      "metadata": {
        "id": "RoYXcOiK0wZs"
      },
      "id": "RoYXcOiK0wZs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0fab182",
      "metadata": {
        "id": "f0fab182"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import gutenberg\n",
        "\n",
        "\n",
        "gutenberg.fileids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb49e8c5",
      "metadata": {
        "id": "fb49e8c5"
      },
      "outputs": [],
      "source": [
        "file = 'blake-poems.txt'\n",
        "\n",
        "data = gutenberg.raw(file)\n",
        "\n",
        "data[0:600]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23a409e0",
      "metadata": {
        "id": "23a409e0"
      },
      "outputs": [],
      "source": [
        "# WARNING: do not crawl Gutenberg aggressively; load one book, don't download all, else IP may get blocked\n",
        "\n",
        "import requests\n",
        "\n",
        "url = 'https://www.gutenberg.org/files/5200/5200-0.txt'\n",
        "\n",
        "data = requests.get(url).text\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2c6a756",
      "metadata": {
        "id": "a2c6a756"
      },
      "outputs": [],
      "source": [
        "url = 'http://english.ryukyushimpo.jp/'\n",
        "\n",
        "data = requests.get(url).text\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6c3f774",
      "metadata": {
        "id": "c6c3f774"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(data, 'html.parser')\n",
        "\n",
        "links = soup.find_all('a', href=True)\n",
        "\n",
        "links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1672576",
      "metadata": {
        "id": "b1672576"
      },
      "outputs": [],
      "source": [
        "len(links)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb176cb6",
      "metadata": {
        "id": "cb176cb6"
      },
      "outputs": [],
      "source": [
        "url = 'http://english.ryukyushimpo.jp/2021/09/03/34020/'\n",
        "\n",
        "data = requests.get(url).text\n",
        "\n",
        "soup = BeautifulSoup(data, 'html.parser')\n",
        "\n",
        "soup.get_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23bea384",
      "metadata": {
        "id": "23bea384"
      },
      "outputs": [],
      "source": [
        "text = soup.get_text()\n",
        "\n",
        "text[0:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "158b1db7",
      "metadata": {
        "id": "158b1db7"
      },
      "outputs": [],
      "source": [
        "text = text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ').replace('\\xa0', ' ')\n",
        "\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "002dca8d",
      "metadata": {
        "id": "002dca8d"
      },
      "outputs": [],
      "source": [
        "cutoff = text.index('Go to Japanese')\n",
        "\n",
        "cutoff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01f72f28",
      "metadata": {
        "id": "01f72f28"
      },
      "outputs": [],
      "source": [
        "text = text[0:cutoff]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c74dce2",
      "metadata": {
        "id": "5c74dce2"
      },
      "outputs": [],
      "source": [
        "cutoff = text.rindex('Hirokazu Ueyonabaru')\n",
        "\n",
        "text = text[cutoff:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51cec5ef",
      "metadata": {
        "id": "51cec5ef"
      },
      "outputs": [],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73bf43d7",
      "metadata": {
        "id": "73bf43d7"
      },
      "source": [
        "# NLTK Part-of-Speech Tagging (Pos-Tagging)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d2750e6",
      "metadata": {
        "id": "1d2750e6"
      },
      "outputs": [],
      "source": [
        "url = 'https://www.gutenberg.org/files/5200/5200-0.txt'\n",
        "\n",
        "text = requests.get(url).text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb2cafd7",
      "metadata": {
        "id": "bb2cafd7"
      },
      "outputs": [],
      "source": [
        "cutoff = text.index('One morning')\n",
        "\n",
        "text = text[cutoff:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63941add",
      "metadata": {
        "id": "63941add"
      },
      "outputs": [],
      "source": [
        "cutoff = text.rindex('*** END OF THE PROJECT GUTENBERG EBOOK METAMORPHOSIS ***')\n",
        "\n",
        "text = text[:cutoff]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b5186fb",
      "metadata": {
        "id": "5b5186fb"
      },
      "outputs": [],
      "source": [
        "text[-500:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70f14758",
      "metadata": {
        "id": "70f14758"
      },
      "outputs": [],
      "source": [
        "text = text.replace('\\r', ' ').replace('\\n', ' ')\n",
        "\n",
        "text[0:505]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11d47f10",
      "metadata": {
        "id": "11d47f10"
      },
      "outputs": [],
      "source": [
        "text = text.replace('â\\x80\\x99', '\\'').replace('â\\x80\\x9c', '\"').replace('â\\x80\\x9d', '\"\"').replace('â\\x80\\x94', ' ')\n",
        "\n",
        "text[0:502]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75c170a8",
      "metadata": {
        "id": "75c170a8"
      },
      "outputs": [],
      "source": [
        "def get_data():\n",
        "\n",
        "    url = 'https://www.gutenberg.org/files/5200/5200-0.txt'\n",
        "    text = requests.get(url).text\n",
        "\n",
        "    # strip header junk\n",
        "    cutoff = text.index('One morning')\n",
        "    text = text[cutoff:]\n",
        "\n",
        "    # strip footer junk\n",
        "    cutoff = text.rindex('*** END OF THE PROJECT GUTENBERG EBOOK METAMORPHOSIS ***')\n",
        "    text = text[:cutoff]\n",
        "\n",
        "    # pre-processing to clean the text\n",
        "    text = text.replace('\\r', ' ').replace('\\n', ' ')\n",
        "    text = text.replace('â\\x80\\x99', '\\'').replace('â\\x80\\x9c', '\"')\\\n",
        "        .replace('â\\x80\\x9d', '\"\"').replace('â\\x80\\x94', ' ')\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "301ed017",
      "metadata": {
        "id": "301ed017"
      },
      "outputs": [],
      "source": [
        "text = get_data()\n",
        "\n",
        "text[0:502]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "5tzO14iQiG78"
      },
      "id": "5tzO14iQiG78",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbccea6a",
      "metadata": {
        "id": "dbccea6a"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "sentences[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "id": "sxhZlu1ciMwB"
      },
      "id": "sxhZlu1ciMwB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47a320ba",
      "metadata": {
        "id": "47a320ba"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.pos_tag(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05ddacd8",
      "metadata": {
        "id": "05ddacd8"
      },
      "outputs": [],
      "source": [
        "sentence = sentences[0]\n",
        "\n",
        "sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e72be1ed",
      "metadata": {
        "id": "e72be1ed"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import casual_tokenize\n",
        "\n",
        "tokens = casual_tokenize(sentence)\n",
        "\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "161f1163",
      "metadata": {
        "id": "161f1163"
      },
      "outputs": [],
      "source": [
        "nltk.pos_tag(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18fad17c",
      "metadata": {
        "id": "18fad17c"
      },
      "outputs": [],
      "source": [
        "entities = []\n",
        "\n",
        "for row in nltk.pos_tag(tokens):\n",
        "\n",
        "    token = row[0]\n",
        "\n",
        "    tag = row[1]\n",
        "\n",
        "    if tag == 'NNP':\n",
        "\n",
        "        entities.append(token)\n",
        "\n",
        "entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c445b619",
      "metadata": {
        "id": "c445b619"
      },
      "outputs": [],
      "source": [
        "def extract_entities(sentence):\n",
        "\n",
        "    entities = []\n",
        "\n",
        "    tokens = casual_tokenize(sentence)\n",
        "\n",
        "    for row in nltk.pos_tag(tokens):\n",
        "\n",
        "        token = row[0]\n",
        "\n",
        "        tag = row[1]\n",
        "\n",
        "        if tag == 'NNP':\n",
        "\n",
        "            entities.append(token)\n",
        "\n",
        "    return entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "357f82d8",
      "metadata": {
        "id": "357f82d8"
      },
      "outputs": [],
      "source": [
        "extract_entities(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7a95de3",
      "metadata": {
        "id": "b7a95de3"
      },
      "outputs": [],
      "source": [
        "entities = [extract_entities(sentence) for sentence in sentences]\n",
        "\n",
        "entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec674b2",
      "metadata": {
        "id": "8ec674b2"
      },
      "outputs": [],
      "source": [
        "def extract_entities(sentence):\n",
        "\n",
        "    entities = []\n",
        "\n",
        "    tokens = casual_tokenize(sentence)\n",
        "\n",
        "    for row in nltk.pos_tag(tokens):\n",
        "\n",
        "        token = row[0]\n",
        "\n",
        "        tag = row[1]\n",
        "\n",
        "        if tag == 'NNP':\n",
        "\n",
        "            entities.append(token)\n",
        "\n",
        "    if len(entities) > 0:\n",
        "\n",
        "        return entities\n",
        "\n",
        "    else:\n",
        "\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03504cc5",
      "metadata": {
        "id": "03504cc5"
      },
      "outputs": [],
      "source": [
        "entities = [extract_entities(sentence) for sentence in sentences]\n",
        "\n",
        "entities[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a470ccdd",
      "metadata": {
        "id": "a470ccdd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'sentence':sentences, 'entities':entities})\n",
        "\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06bee130",
      "metadata": {
        "id": "06bee130"
      },
      "outputs": [],
      "source": [
        "df = df.dropna()\n",
        "\n",
        "df = df[df['entities'].apply(len) > 1]\n",
        "\n",
        "entities = df['entities'].to_list()\n",
        "\n",
        "entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcc97721",
      "metadata": {
        "id": "dcc97721"
      },
      "outputs": [],
      "source": [
        "def extract_entities(sentence):\n",
        "\n",
        "    entities = []\n",
        "\n",
        "    tokens = casual_tokenize(sentence)\n",
        "\n",
        "    for row in nltk.pos_tag(tokens):\n",
        "\n",
        "        token = row[0]\n",
        "\n",
        "        tag = row[1]\n",
        "\n",
        "        if tag == 'NNP':\n",
        "\n",
        "            if \"'\" in token:\n",
        "\n",
        "                cutoff = token.index('\\'')\n",
        "\n",
        "                token = token[:cutoff]\n",
        "\n",
        "            entities.append(token)\n",
        "\n",
        "    if len(entities) > 0:\n",
        "\n",
        "        return entities\n",
        "\n",
        "    else:\n",
        "\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b6601c6",
      "metadata": {
        "id": "5b6601c6"
      },
      "outputs": [],
      "source": [
        "entities = [extract_entities(sentence) for sentence in sentences]\n",
        "\n",
        "entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a31432dd",
      "metadata": {
        "id": "a31432dd"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'sentence':sentences, 'entities':entities})\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "df = df[df['entities'].apply(len) > 1]\n",
        "\n",
        "entities = df['entities'].to_list()\n",
        "\n",
        "entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29317dea",
      "metadata": {
        "id": "29317dea"
      },
      "outputs": [],
      "source": [
        "from string import punctuation\n",
        "\n",
        "def extract_entities(sentence):\n",
        "\n",
        "    entities = []\n",
        "\n",
        "    tokens = casual_tokenize(sentence)\n",
        "\n",
        "    for row in nltk.pos_tag(tokens):\n",
        "\n",
        "        token = row[0]\n",
        "\n",
        "        tag = row[1]\n",
        "\n",
        "        if tag == 'NNP':\n",
        "\n",
        "            for p in punctuation:\n",
        "\n",
        "                if p in token:\n",
        "\n",
        "                    cutoff = token.index(p)\n",
        "\n",
        "                    token = token[:cutoff]\n",
        "\n",
        "            if len(token) > 1:\n",
        "\n",
        "                entities.append(token)\n",
        "\n",
        "    if len(entities) > 0:\n",
        "\n",
        "        return entities\n",
        "\n",
        "    else:\n",
        "\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df38e1db",
      "metadata": {
        "id": "df38e1db"
      },
      "outputs": [],
      "source": [
        "entities = [extract_entities(sentence) for sentence in sentences]\n",
        "\n",
        "df = pd.DataFrame({'sentence':sentences, 'entities':entities})\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "df = df[df['entities'].apply(len) > 1]\n",
        "\n",
        "entities = df['entities'].to_list()\n",
        "\n",
        "entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff1d30c8",
      "metadata": {
        "id": "ff1d30c8"
      },
      "outputs": [],
      "source": [
        "def get_book_entities():\n",
        "\n",
        "    text = get_data()\n",
        "\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    entities = [extract_entities(sentence) for sentence in sentences]\n",
        "\n",
        "    df = pd.DataFrame({'sentence':sentences, 'entities':entities})\n",
        "\n",
        "    df = df.dropna()\n",
        "\n",
        "    df = df[df['entities'].apply(len) > 1]\n",
        "\n",
        "    entities = df['entities'].to_list()\n",
        "\n",
        "    return entities,df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c062125",
      "metadata": {
        "id": "5c062125"
      },
      "outputs": [],
      "source": [
        "entities, df = get_book_entities()\n",
        "\n",
        "entities[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "JMLrWqHT4iv7"
      },
      "id": "JMLrWqHT4iv7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d86a0479",
      "metadata": {
        "id": "d86a0479"
      },
      "source": [
        "# spaCy Pos-Tagging"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "id": "piaG42sLi0ix"
      },
      "id": "piaG42sLi0ix",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51649227",
      "metadata": {
        "id": "51649227"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5683941d",
      "metadata": {
        "id": "5683941d"
      },
      "outputs": [],
      "source": [
        "def get_data():\n",
        "\n",
        "    url = 'https://www.gutenberg.org/files/5200/5200-0.txt'\n",
        "    text = requests.get(url).text\n",
        "\n",
        "    # strip header junk\n",
        "    cutoff = text.index('One morning')\n",
        "    text = text[cutoff:]\n",
        "\n",
        "    # strip footer junk\n",
        "    cutoff = text.rindex('*** END OF THE PROJECT GUTENBERG EBOOK METAMORPHOSIS ***')\n",
        "    text = text[:cutoff]\n",
        "\n",
        "    # pre-processing to clean the text\n",
        "    text = text.replace('\\r', ' ').replace('\\n', ' ')\n",
        "    text = text.replace('â\\x80\\x99', '\\'').replace('â\\x80\\x9c', '\"').replace('â\\x80\\x9d', '\"\"').replace('â\\x80\\x94', ' ')\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f69635e1",
      "metadata": {
        "id": "f69635e1"
      },
      "outputs": [],
      "source": [
        "text = get_data()\n",
        "\n",
        "text[0:279]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "761639fb",
      "metadata": {
        "id": "761639fb"
      },
      "outputs": [],
      "source": [
        "doc = nlp(text)\n",
        "\n",
        "sentences = list(doc.sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6acae628",
      "metadata": {
        "id": "6acae628"
      },
      "outputs": [],
      "source": [
        "for s in sentences[0:6]:\n",
        "\n",
        "    print(s)\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e1a8a6b",
      "metadata": {
        "id": "9e1a8a6b"
      },
      "outputs": [],
      "source": [
        "for token in sentences[0]:\n",
        "\n",
        "    print('{}: {}'.format(token.text, token.tag_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9563feaa",
      "metadata": {
        "id": "9563feaa"
      },
      "outputs": [],
      "source": [
        "for token in sentences[0]:\n",
        "\n",
        "    print('{}: {}'.format(token.text, token.pos_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e9974bb",
      "metadata": {
        "id": "5e9974bb"
      },
      "outputs": [],
      "source": [
        "entities = []\n",
        "\n",
        "for token in sentences[0]:\n",
        "\n",
        "    if token.tag_ == 'NNP':\n",
        "\n",
        "        entities.append(token.text)\n",
        "\n",
        "entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf8dc05e",
      "metadata": {
        "id": "cf8dc05e"
      },
      "outputs": [],
      "source": [
        "entities = []\n",
        "\n",
        "for sentence in sentences:\n",
        "\n",
        "    sentence_entities = []\n",
        "\n",
        "    for token in sentence:\n",
        "\n",
        "        if token.tag_ == 'NNP':\n",
        "\n",
        "            sentence_entities.append(token.text)\n",
        "\n",
        "    entities.append(sentence_entities)\n",
        "\n",
        "entities[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e7117cd",
      "metadata": {
        "id": "6e7117cd"
      },
      "outputs": [],
      "source": [
        "def extract_entities(text):\n",
        "\n",
        "    doc = nlp(text)\n",
        "\n",
        "    sentences = list(doc.sents)\n",
        "\n",
        "    entities = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "\n",
        "        sentence_entities = []\n",
        "\n",
        "        for token in sentence:\n",
        "\n",
        "            if token.tag_ == 'NNP':\n",
        "\n",
        "                sentence_entities.append(token.text)\n",
        "\n",
        "        if len(sentence_entities) > 0:\n",
        "\n",
        "            entities.append(sentence_entities)\n",
        "\n",
        "    return entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93a2f238",
      "metadata": {
        "id": "93a2f238"
      },
      "outputs": [],
      "source": [
        "extract_entities(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f09fc6a",
      "metadata": {
        "id": "5f09fc6a"
      },
      "source": [
        "# spaCy NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb46330",
      "metadata": {
        "id": "cbb46330"
      },
      "outputs": [],
      "source": [
        "for token in sentences[0]:\n",
        "\n",
        "    print('{}: {}'.format(token.text, token.ent_type_))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[0].text"
      ],
      "metadata": {
        "id": "3i7t6ikFNcOf"
      },
      "id": "3i7t6ikFNcOf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e1fb1fb",
      "metadata": {
        "id": "5e1fb1fb"
      },
      "outputs": [],
      "source": [
        "doc = nlp(sentences[0].text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "\n",
        "    print('{}: {}'.format(ent, ent.label_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdfc17f3",
      "metadata": {
        "id": "cdfc17f3"
      },
      "outputs": [],
      "source": [
        "def extract_entities(text):\n",
        "\n",
        "    doc = nlp(text)\n",
        "\n",
        "    sentences = list(doc.sents)\n",
        "\n",
        "    entities = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "\n",
        "        sentence_entities = []\n",
        "\n",
        "        sent_doc = nlp(sentence.text)\n",
        "\n",
        "        for ent in sent_doc.ents:\n",
        "\n",
        "            if ent.label_ in ['PERSON', 'ORG', 'GPE']:\n",
        "\n",
        "                entity = ent.text.strip()\n",
        "\n",
        "                if \"'s\" in entity:\n",
        "\n",
        "                    cutoff = entity.index(\"'s\")\n",
        "\n",
        "                    entity = entity[:cutoff]\n",
        "\n",
        "                if entity != '':\n",
        "\n",
        "                    sentence_entities.append(entity)\n",
        "\n",
        "        sentence_entities = list(set(sentence_entities))\n",
        "\n",
        "        if len(sentence_entities) > 1:\n",
        "\n",
        "            entities.append(sentence_entities)\n",
        "\n",
        "    return entities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "id": "yle0YMiRN93j"
      },
      "id": "yle0YMiRN93j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "id": "4IZYrvz1Vgmj"
      },
      "id": "4IZYrvz1Vgmj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b24f32",
      "metadata": {
        "id": "a3b24f32"
      },
      "outputs": [],
      "source": [
        "morph_entities = extract_entities(text)\n",
        "\n",
        "morph_entities[10:20]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(morph_entities)"
      ],
      "metadata": {
        "id": "tu2EKUCwVX0l"
      },
      "id": "tu2EKUCwVX0l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morph_entities"
      ],
      "metadata": {
        "id": "2qt3LvndVbaq"
      },
      "id": "2qt3LvndVbaq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cbe8faf",
      "metadata": {
        "id": "5cbe8faf"
      },
      "outputs": [],
      "source": [
        "def get_data():\n",
        "\n",
        "    url = 'https://www.gutenberg.org/files/11/11-0.txt'\n",
        "    text = requests.get(url).text\n",
        "\n",
        "    # strip header junk\n",
        "    cutoff = text.index('Alice was beginning')\n",
        "    text = text[cutoff:]\n",
        "\n",
        "    # strip footer junk\n",
        "    cutoff = text.rindex('THE END')\n",
        "    text = text[:cutoff]\n",
        "\n",
        "    # pre-processing to clean the text\n",
        "    text = text.replace('\\r', ' ').replace('\\n', ' ')\n",
        "    text = text.replace('â\\x80\\x99', '\\'').replace('â\\x80\\x9c', '\"').replace('â\\x80\\x9d', '\"\"').replace('â\\x80\\x94', ' ')\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0025dd1a",
      "metadata": {
        "id": "0025dd1a"
      },
      "outputs": [],
      "source": [
        "text = get_data()\n",
        "\n",
        "text[0:310]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df08c993",
      "metadata": {
        "id": "df08c993"
      },
      "outputs": [],
      "source": [
        "alice_entities = extract_entities(text)\n",
        "\n",
        "alice_entities[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef03c582",
      "metadata": {
        "id": "ef03c582"
      },
      "source": [
        "# Converting entities to network data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d485bdb",
      "metadata": {
        "id": "3d485bdb"
      },
      "outputs": [],
      "source": [
        "alice_entities[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82bfe38f",
      "metadata": {
        "id": "82bfe38f"
      },
      "outputs": [],
      "source": [
        "final_sources = []\n",
        "final_targets = []\n",
        "\n",
        "for row in alice_entities:\n",
        "\n",
        "    source = row[0]\n",
        "    targets = row[1:]\n",
        "\n",
        "    for target in targets:\n",
        "\n",
        "        final_sources.append(source)\n",
        "        final_targets.append(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5c03995",
      "metadata": {
        "id": "a5c03995"
      },
      "outputs": [],
      "source": [
        "final_sources[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7be1e6f4",
      "metadata": {
        "id": "7be1e6f4"
      },
      "outputs": [],
      "source": [
        "final_targets[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54710214",
      "metadata": {
        "id": "54710214"
      },
      "outputs": [],
      "source": [
        "def get_network_data(entities):\n",
        "\n",
        "    final_sources = []\n",
        "    final_targets = []\n",
        "\n",
        "    for row in entities:\n",
        "\n",
        "        source = row[0]\n",
        "        targets = row[1:]\n",
        "\n",
        "        for target in targets:\n",
        "\n",
        "            final_sources.append(source)\n",
        "            final_targets.append(target)\n",
        "\n",
        "    df = pd.DataFrame({'source':final_sources, 'target':final_targets})\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2eeb612",
      "metadata": {
        "id": "a2eeb612"
      },
      "outputs": [],
      "source": [
        "alice_network_df = get_network_data(alice_entities)\n",
        "\n",
        "alice_network_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb3d501",
      "metadata": {
        "id": "6fb3d501"
      },
      "outputs": [],
      "source": [
        "morph_network_df = get_network_data(morph_entities)\n",
        "\n",
        "morph_network_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0cd4c54",
      "metadata": {
        "id": "d0cd4c54"
      },
      "source": [
        "# Converting network data into networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fac28c29",
      "metadata": {
        "id": "fac28c29"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "\n",
        "G_alice = nx.from_pandas_edgelist(alice_network_df)\n",
        "\n",
        "G_morph = nx.from_pandas_edgelist(morph_network_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c84e94a",
      "metadata": {
        "id": "3c84e94a"
      },
      "outputs": [],
      "source": [
        "print(G_alice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28ad2f83",
      "metadata": {
        "id": "28ad2f83"
      },
      "outputs": [],
      "source": [
        "print(G_morph)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-network"
      ],
      "metadata": {
        "id": "mtKjockuj66L"
      },
      "id": "mtKjockuj66L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nx.to_scipy_sparse_array"
      ],
      "metadata": {
        "id": "RE2ELZT6lBRw"
      },
      "id": "RE2ELZT6lBRw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2974c75",
      "metadata": {
        "id": "a2974c75"
      },
      "outputs": [],
      "source": [
        "def draw_graph(G, show_names=False, node_size=1, font_size=10, edge_width=0.5):\n",
        "\n",
        "    import numpy as np\n",
        "    import networkx as nx\n",
        "\n",
        "    from IPython.display import SVG\n",
        "    from sknetwork.visualization import svg_graph\n",
        "    from sknetwork.data import Bunch\n",
        "    from sknetwork.ranking import PageRank\n",
        "    import scipy.sparse as sp\n",
        "\n",
        "    adjacency = nx.adjacency_matrix(G, weight='weight')\n",
        "    adjacency = sp.csr_matrix(adjacency)\n",
        "\n",
        "    names = np.array(list(G.nodes()))\n",
        "\n",
        "    graph = Bunch()\n",
        "    graph.adjacency = adjacency\n",
        "    graph.names = np.array(names)\n",
        "\n",
        "    pagerank = PageRank()\n",
        "\n",
        "    pagerank.fit(adjacency)\n",
        "    scores = pagerank.scores_\n",
        "\n",
        "    if show_names:\n",
        "\n",
        "        image = svg_graph(graph.adjacency, font_size=font_size, node_size=node_size, names=graph.names, width=700, height=500, scores=scores, edge_width=edge_width)\n",
        "\n",
        "    else:\n",
        "\n",
        "        image = svg_graph(graph.adjacency, node_size=node_size, width=700, height=500, scores = scores, edge_width=edge_width)\n",
        "\n",
        "    return SVG(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02e2389a",
      "metadata": {
        "id": "02e2389a"
      },
      "outputs": [],
      "source": [
        "def draw_ego_graph(G, ego, center=True, k=0, show_names=True, edge_width=0.1, node_size=3, font_size=12):\n",
        "\n",
        "    ego = nx.ego_graph(G, ego, center=center)\n",
        "\n",
        "    ego = nx.k_core(ego, k)\n",
        "\n",
        "    return draw_graph(ego, node_size=node_size, font_size=font_size, show_names=show_names, edge_width=edge_width)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KSiZraL8lwV_"
      },
      "id": "KSiZraL8lwV_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbcaa146",
      "metadata": {
        "id": "dbcaa146"
      },
      "outputs": [],
      "source": [
        "draw_graph(G_alice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00f27d7e",
      "metadata": {
        "id": "00f27d7e"
      },
      "outputs": [],
      "source": [
        "draw_graph(G_alice, edge_width=0.2, node_size=3, show_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "129c0e7a",
      "metadata": {
        "id": "129c0e7a"
      },
      "outputs": [],
      "source": [
        "draw_graph(G_alice, edge_width=0.2, node_size=2, show_names=True, font_size=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6243ebe4",
      "metadata": {
        "id": "6243ebe4"
      },
      "outputs": [],
      "source": [
        "draw_ego_graph(G_alice, 'Alice')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6715cf8d",
      "metadata": {
        "id": "6715cf8d"
      },
      "outputs": [],
      "source": [
        "draw_ego_graph(G_alice, 'Alice', center=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4bf2a80",
      "metadata": {
        "id": "c4bf2a80"
      },
      "outputs": [],
      "source": [
        "draw_ego_graph(G_alice, 'Alice', center=False, k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e952172",
      "metadata": {
        "id": "0e952172"
      },
      "outputs": [],
      "source": [
        "draw_graph(G_morph, show_names=True, node_size=3, font_size=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41c456d3",
      "metadata": {
        "id": "41c456d3"
      },
      "outputs": [],
      "source": [
        "morph_network_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28be6cdc",
      "metadata": {
        "id": "28be6cdc"
      },
      "outputs": [],
      "source": [
        "morph_network_df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2EexHspHms0j"
      },
      "id": "2EexHspHms0j",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}